{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. \n",
    "\n",
    "Given an alphabet of 26 letters, there are 26 to the power 10, or 26 ** 10, ten-letter strings we can form. That works out to 141167095653376. How many hundred-letter strings are possible?\n",
    "\n",
    "\n",
    "Given alphabet of size $A$ there are $A^n$ possible strings of length $n$. Thus with a 26-letter alphabet there are $26^{100}$ possible 100-character strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3.\n",
    "\n",
    "The Python multiplication operation can be applied to lists. What happens when you type ['Monty', 'Python'] * 20, or 3 * sent1?\n",
    "\n",
    "Multiplication on iterables in Python works like concatenation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monty', 'Python', 'Monty', 'Python']\n",
      "Sentence 1: ['Call', 'me', 'Ishmael', '.']\n",
      "3 * sent1 = ['Call', 'me', 'Ishmael', '.', 'Call', 'me', 'Ishmael', '.', 'Call', 'me', 'Ishmael', '.']\n"
     ]
    }
   ],
   "source": [
    "print(['Monty', 'Python'] * 2)\n",
    "print(f\"Sentence 1: {sent1}\\n3 * sent1 = {3*sent1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "How many words are there in text2? How many distinct words are there?\n",
    "\n",
    "If we consider 'words' to be only alphabetical tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 120733\n",
      "Number of unique words: 6713\n"
     ]
    }
   ],
   "source": [
    "words2 = [w for w in text2 if w.isalpha()]\n",
    "print(f\"Number of words: {len(words2)}\")\n",
    "print(f\"Number of unique words: {len(set(words2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So roughly 5.6% of words used are distinct. \n",
    "\n",
    "If we consider 'words' to be all tokens as tokenized by NLTK we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 141576\n",
      "Number of unique words: 6833\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of words: {len(text2)}\")\n",
    "print(f\"Number of unique words: {len(set(text2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or roughly 4.8% of words used are distinct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Compare the lexical diversity scores for humor and romance fiction in 1.1. Which genre is more lexically diverse?\n",
    "\n",
    "We'll use the Monty Python text (`text6`) for the humor category and Jane Austen (`text2`) for romance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lex. Diversity Monty Python: 0.1276595744680851\n",
      "Lex. Diversity Austen: 0.04826383002768831\n",
      "Python is  2.645 times more lexically diverse\n"
     ]
    }
   ],
   "source": [
    "# Humor: Monty Python. Romance: Sense & Sensibility\n",
    "diversity_mp = lexical_diversity(text6)\n",
    "diversity_ss = lexical_diversity(text2)\n",
    "print(f\"Lex. Diversity Monty Python: {diversity_mp}\")\n",
    "print(f\"Lex. Diversity Austen: {diversity_ss}\")\n",
    "print(f\"Python is  {round(diversity_mp / diversity_ss, 3)} times more lexically diverse\")\n",
    "# Monty Python has a lexical diversity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce a dispersion plot of the four main protagonists in Sense and Sensibility: Elinor, Marianne, Edward, and Willoughby. \n",
    "\n",
    "What can you observe about the different roles played by the males and females in this novel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text2.dispersion_plot(['Elinor', 'Marianne', 'Edward', 'Willoughby'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the women are consistently appearing throughout the book, but Edward and Willoughby basically trade off intervals in the book in which they are mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "Find the collocations in `text5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wanna chat',\n",
       " 'PART JOIN',\n",
       " 'MODE #14-19teens',\n",
       " 'JOIN PART',\n",
       " 'PART PART',\n",
       " 'cute.-ass MP3',\n",
       " 'MP3 player',\n",
       " 'JOIN JOIN',\n",
       " 'times .. .',\n",
       " 'ACTION watches',\n",
       " 'guys wanna',\n",
       " 'song lasts',\n",
       " 'last night',\n",
       " 'ACTION sits',\n",
       " '-...)...- S.M.R.',\n",
       " 'Lime Player',\n",
       " 'Player 12%',\n",
       " 'dont know',\n",
       " 'lez gurls',\n",
       " 'long time']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5.collocation_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "\n",
    "Consider the following Python expression: `len(set(text4))`. State the purpose of this expression. Describe the two steps involved in performing this computation.\n",
    "\n",
    "This expression returns the unique number of tokens in `text4`. The first step, `set()`, converts the token collection `text4` to a set type, which removes duplicates (since `set` elements must be unique). Then calling `len()` on the result returns the number of tokens in the set, or in other words, the number of tokens in `text4` after all duplicates have been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9b\n",
    "\n",
    "Try adding the string to itself using `my_string + my_string`, or multiplying it by a number, e.g., `my_string * 3`. Notice that the strings are joined together without any spaces. How could you fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foobar foobar foobar\n"
     ]
    }
   ],
   "source": [
    "def repeatString(text, n):\n",
    "    return \" \".join([text] * n)\n",
    "    \n",
    "print(repeatString(\"foobar\", 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10\n",
    "\n",
    "Define a variable my_sent to be a list of words, using the syntax my_sent = [\"My\", \"sent\"] (but with your own words, or a favorite saying).\n",
    "\n",
    "### 10a \n",
    "Use `' '.join(my_sent)` to convert this into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_string: It's almost time to go to bed.\n",
      "type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "my_sent = [\"It's\", \"almost\", \"time\", \"to\", \"go\", \"to\", \"bed\"]\n",
    "my_string = ' '.join(my_sent)\n",
    "print(f\"my_string: {my_string + '.'}\\ntype: {type(my_string)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10b\n",
    "Use split() to split the string back into the list form you had to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"It's\", 'almost', 'time', 'to', 'go', 'to', 'bed']\n"
     ]
    }
   ],
   "source": [
    "my_split = my_string.split()\n",
    "print(f\"{my_split}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 11\n",
    "\n",
    "Define several variables containing lists of words, e.g., `phrase1, phrase2`, and so on. Join them together in various combinations (using the plus operator) to form whole sentences. What is the relationship between `len(phrase1 + phrase2)` and `len(phrase1) + len(phrase2)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPhrases(phrase1, phrase2):\n",
    "    len1, len2 = len(phrase1), len(phrase2)\n",
    "    combined = phrase1 + phrase2\n",
    "    print(combined)\n",
    "    print(f\"len(phrase1) + len(phrase2) = {len1} + {len2} = {len1 + len2}\")\n",
    "    print(f\"len(combined) = {len(combined)}\")\n",
    "    print('*' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = ['Have', 'you', 'ever']\n",
    "p2 = ['Would', 'they', 'like', 'to']\n",
    "p3 = ['Could', 'it', 'be', 'that', 'I']\n",
    "p4 = ['wanted', 'to', 'eat', 'a', 'whole', 'pizza']\n",
    "p5 = ['run', 'off', 'with', 'the', 'circus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Have', 'you', 'ever', 'wanted', 'to', 'eat', 'a', 'whole', 'pizza']\n",
      "len(phrase1) + len(phrase2) = 3 + 6 = 9\n",
      "len(combined) = 9\n",
      "****************************************\n",
      "['Have', 'you', 'ever', 'run', 'off', 'with', 'the', 'circus']\n",
      "len(phrase1) + len(phrase2) = 3 + 5 = 8\n",
      "len(combined) = 8\n",
      "****************************************\n",
      "['Would', 'they', 'like', 'to', 'wanted', 'to', 'eat', 'a', 'whole', 'pizza']\n",
      "len(phrase1) + len(phrase2) = 4 + 6 = 10\n",
      "len(combined) = 10\n",
      "****************************************\n",
      "['Would', 'they', 'like', 'to', 'run', 'off', 'with', 'the', 'circus']\n",
      "len(phrase1) + len(phrase2) = 4 + 5 = 9\n",
      "len(combined) = 9\n",
      "****************************************\n",
      "['Could', 'it', 'be', 'that', 'I', 'wanted', 'to', 'eat', 'a', 'whole', 'pizza']\n",
      "len(phrase1) + len(phrase2) = 5 + 6 = 11\n",
      "len(combined) = 11\n",
      "****************************************\n",
      "['Could', 'it', 'be', 'that', 'I', 'run', 'off', 'with', 'the', 'circus']\n",
      "len(phrase1) + len(phrase2) = 5 + 5 = 10\n",
      "len(combined) = 10\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "_ = [printPhrases(phr1, phr2) for phr1, phr2 in itertools.product([p1, p2, p3], [p4, p5])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12\n",
    "\n",
    "Consider the following two expressions, which have the same value. Which one will typically be more relevant in NLP? Why?\n",
    "\n",
    "`\"Monty Python\"[6:12]\n",
    "[\"Monty\", \"Python\"][1]`\n",
    "\n",
    "The second will be more relevant since we do more work on word tokens than character tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 13\n",
    "\n",
    "We have seen how to represent a sentence as a list of words, where each word is a sequence of characters. What does `sent1[2][2]` do? Why? Experiment with other index values.\n",
    "\n",
    "The command `sent1[2][2]` returns the 3rd character of the 3rd token in `sent1`. In general, `sent1[i][j]` will return the $j+1$th character of the $i+1$th token in the sentence. If the indices are out of bounds then Python returns an IndexError."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 14\n",
    "\n",
    "The first sentence of `text3` is provided to you in the variable `sent3`. The index of `the` in `sent3` is 1, because `sent3[1]` gives us 'the'. What are the indexes of the two other occurrences of this word in `sent3`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 8]\n"
     ]
    }
   ],
   "source": [
    "# Get all indices of sent3 == 'the'\n",
    "print([i for i in range(len(sent3)) if sent3[i] == 'the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 15\n",
    "\n",
    "Review the discussion of conditionals in 4. Find all words in the Chat Corpus (text5) starting with the letter b. Show them in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'BAAAAALLLLLLLLIIIIIIINNNNNNNNNNN', 'BE', 'BIG', 'BLONDES', 'BOOTS', 'BOOTY', 'BOY', 'BUT', 'BUt', 'BYE', 'Back', 'Barbieee', 'Barometer', 'Beach', 'Because', 'Been', 'Ben', 'Benjamin', 'Better', 'Bible', 'Biiiiiitch', 'Biographys', 'Birdgang', 'Bloooooooood', 'Bloooooooooood', 'Bloooooooooooood', 'Bone', 'Bonus', 'Books', 'Boone', 'Booyah', 'Borat', 'Born', 'Box', 'Boyz', 'Break', 'Breaking', 'Broken', 'Bud', 'Burger', 'But', 'Bwhaha', 'Bye', 'b', 'b-day', 'b/c', 'b4', 'babay', 'babble', 'babblein', 'babe', 'babes', 'babi', 'babies', 'babiess', 'baby', 'babycakeses', 'bachelorette', 'back', 'backatchya', 'backfrontsidewaysandallaroundtheworld', 'backroom', 'backup', 'bacl', 'bad', 'bag', 'bagel', 'bagels', 'bahahahaa', 'bak', 'baked', 'balad', 'balance', 'balck', 'ball', 'ballin', 'balls', 'ban', 'band', 'bandito', 'bandsaw', 'banjoes', 'banned', 'baord', 'bar', 'barbie', 'bare', 'barely', 'bares', 'barfights', 'barks', 'barn', 'barrel', 'base', 'bases', 'basically', 'basket', 'battery', 'bay', 'bbbbbyyyyyyyeeeeeeeee', 'bbiam', 'bbl', 'bbs', 'bc', 'be', 'beach', 'beachhhh', 'beam', 'beams', 'beanbag', 'beans', 'bear', 'bears', 'beat', 'beaten', 'beatles', 'beats', 'beattles', 'beautiful', 'because', 'beckley', 'become', 'bed', 'bedford', 'bedroom', 'beeeeehave', 'beeehave', 'been', 'beer', 'before', 'beg', 'begin', 'behave', 'behind', 'bein', 'being', 'beleive', 'believe', 'belive', 'bell', 'belly', 'belong', 'belongings', 'ben', 'bend', 'benz', 'bes', 'beside', 'besides', 'best', 'bet', 'betrayal', 'betta', 'better', 'between', 'beuty', 'bf', 'bi', 'biatch', 'bible', 'biebsa', 'bied', 'big', 'bigest', 'biggest', 'biiiatch', 'bike', 'bikes', 'bikini', 'bio', 'bird', 'birfday', 'birthday', 'bisexual', 'bishes', 'bit', 'bitch', 'bitches', 'bitdh', 'bite', 'bites', 'biyatch', 'biz', 'bj', 'black', 'blade', 'blah', 'blank', 'blankie', 'blazed', 'bleach', 'blech', 'bless', 'blessings', 'blew', 'blind', 'blinks', 'bliss', 'blocking', 'bloe', 'blood', 'blooded', 'bloody', 'blow', 'blowing', 'blowjob', 'blowup', 'blue', 'blueberry', 'bluer', 'blues', 'blunt', 'board', 'bob', 'bodies', 'body', 'boed', 'boght', 'boi', 'boing', 'boinked', 'bois', 'bomb', 'bone', 'boned', 'bones', 'bong', 'boning', 'bonus', 'boo', 'booboo', 'boobs', 'book', 'boom', 'boooooooooooglyyyyyy', 'boost', 'boot', 'bootay', 'booted', 'boots', 'booty', 'border', 'borderline', 'bored', 'boredom', 'boring', 'born', 'born-again', 'bosom', 'boss', 'bossy', 'bot', 'both', 'bother', 'bothering', 'bottle', 'bought', 'bounced', 'bouncer', 'bouncers', 'bound', 'bout', 'bouts', 'bow', 'bowl', 'box', 'boy', 'boyfriend', 'boys', 'bra', 'brad', 'brady', 'brain', 'brakes', 'brass', 'brat', 'brb', 'brbbb', 'bread', 'break', 'breaks', 'breath', 'breathe', 'bred', 'breeding', 'bright', 'brightened', 'bring', 'brings', 'bro', 'broke', 'brooklyn', 'brother', 'brothers', 'brought', 'brown', 'brrrrrrr', 'bruises', 'brunswick', 'brwn', 'btw', 'bucks', 'buddyyyyyy', 'buff', 'buffalo', 'bug', 'bugs', 'buh', 'build', 'builds', 'built', 'bull', 'bulls', 'bum', 'bumber', 'bummer', 'bumped', 'bumper', 'bunch', 'bunny', 'burger', 'burito', 'burned', 'burns', 'burp', 'burpin', 'burps', 'burried', 'burryed', 'bus', 'buses', 'bust', 'busted', 'busy', 'but', 'butt', 'butter', 'butterscotch', 'button', 'buttons', 'buy', 'buying', 'bwahahahahahahahahahaha', 'by', 'byb', 'bye', 'byeee', 'byeeee', 'byeeeeeeee', 'byeeeeeeeeeeeee', 'byes']\n"
     ]
    }
   ],
   "source": [
    "# N.B. there is an empty string in text5 so we cannot index\n",
    "b_words = list(set([word for word in text5 if len(word) != 0 and word[0] in ['b', 'B']]))\n",
    "b_words.sort()\n",
    "print(b_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 17\n",
    "\n",
    "Use `text9.index()` to find the index of the word sunset. You'll need to insert this word as an argument between the parentheses. By a process of trial and error, find the slice for the complete sentence that contains this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 629\n",
      "['the', 'sunset']\n",
      "['on', 'the', 'sunset', 'side']\n",
      "['lay', 'on', 'the', 'sunset', 'side', 'of']\n",
      "['Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London']\n",
      "['Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',']\n",
      "['of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as']\n",
      "['suburb', 'of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as', 'red']\n",
      "['THE', 'suburb', 'of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as', 'red', 'and']\n",
      "['PARK', 'THE', 'suburb', 'of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as', 'red', 'and', 'ragged']\n",
      "['SAFFRON', 'PARK', 'THE', 'suburb', 'of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as', 'red', 'and', 'ragged', 'as']\n",
      "['OF', 'SAFFRON', 'PARK', 'THE', 'suburb', 'of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as', 'red', 'and', 'ragged', 'as', 'a']\n",
      "['POETS', 'OF', 'SAFFRON', 'PARK', 'THE', 'suburb', 'of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as', 'red', 'and', 'ragged', 'as', 'a', 'cloud']\n",
      "['TWO', 'POETS', 'OF', 'SAFFRON', 'PARK', 'THE', 'suburb', 'of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as', 'red', 'and', 'ragged', 'as', 'a', 'cloud', 'of']\n",
      "['THE', 'TWO', 'POETS', 'OF', 'SAFFRON', 'PARK', 'THE', 'suburb', 'of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as', 'red', 'and', 'ragged', 'as', 'a', 'cloud', 'of', 'sunset']\n",
      "['I', 'THE', 'TWO', 'POETS', 'OF', 'SAFFRON', 'PARK', 'THE', 'suburb', 'of', 'Saffron', 'Park', 'lay', 'on', 'the', 'sunset', 'side', 'of', 'London', ',', 'as', 'red', 'and', 'ragged', 'as', 'a', 'cloud', 'of', 'sunset', '.']\n"
     ]
    }
   ],
   "source": [
    "idx = text9.index('sunset')\n",
    "print(f\"Index: {idx}\")\n",
    "# Try wider and wider slices until sentences comes into view\n",
    "for i in range(1, 16):\n",
    "    print(text9[idx-i:idx+i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(text9[idx-8:idx+15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 18\n",
    "\n",
    "Using list addition, and the set and sorted operations, compute the vocabulary of the sentences sent1 ... sent8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', ',', '-', '.', '1', '25', '29', '61', ':', 'ARTHUR', 'Call', 'Citizens', 'Dashwood', 'Fellow', 'God', 'House', 'I', 'In', 'Ishmael', 'JOIN']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(set(sent1 + sent2 + sent3 + sent4 + sent5 + sent6 + sent7 + sent8))\n",
    "vocabulary.sort()\n",
    "print(vocabulary[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 19\n",
    "\n",
    "What is the difference between the following two lines? Which one will give a larger value? Will this be the case for other texts?\n",
    "\n",
    " \t\n",
    "`>>> sorted(set(w.lower() for w in text1))`\n",
    "\n",
    "`>>> sorted(w.lower() for w in set(text1))`\n",
    "\n",
    "The second is potentially larger because it first gets uniques via `set(text1)`, then casts to lowercase. For instance \"foo\" and \"Foo\" will both be included in the resulting set, then both cast to lowercase. In the first version, both tokens would be cast to lowercase first, then the `set()` operation would include only one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 20\n",
    "\n",
    "What is the difference between the following two tests: `w.isupper()` and not `w.islower()`?\n",
    "\n",
    "The method `.isupper()` returns `True` if *all* the characters in the word are uppercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"FOO\".isupper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, `not w.islower()` returns `True` if it is not the case that all characters in `w` are lowercase; that is it will return `True` if there is one or more non-lowercase letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not \"Foo\".islower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 21\n",
    "\n",
    "Write the slice expression that extracts the last two words of `text2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE', 'END']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 22\n",
    "\n",
    "Find all the four-letter words in the Chat Corpus (`text5`). With the help of a frequency distribution (FreqDist), show these words in decreasing order of frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['left', 'with', 'this', 'name', 'PART', 'well', 'NICK', 'name', 'U121', 'golf']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({'JOIN': 1021, 'PART': 1016, 'that': 274, 'what': 183, 'here': 181, '....': 170, 'have': 164, 'like': 156, 'with': 152, 'chat': 142, ...})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [w for w in text5 if len(w) == 4]\n",
    "print(words[:10])\n",
    "FreqDist(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 23\n",
    "\n",
    "Review the discussion of looping with conditions in 4. Use a combination of for and if statements to loop over the words of the movie script for Monty Python and the Holy Grail (`text6`) and print all the uppercase words, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCENE\n",
      "KING\n",
      "ARTHUR\n",
      "SOLDIER\n",
      "ARTHUR\n",
      "I\n",
      "SOLDIER\n",
      "ARTHUR\n",
      "I\n",
      "I\n",
      "SOLDIER\n",
      "ARTHUR\n",
      "SOLDIER\n",
      "ARTHUR\n",
      "SOLDIER\n",
      "ARTHUR\n",
      "SOLDIER\n"
     ]
    }
   ],
   "source": [
    "for word in text6[:200]:\n",
    "    if word.isupper():\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 24\n",
    "Write expressions for finding all words in text6 that meet the conditions listed below. The result should be in the form of a list of words: ['word1', 'word2', ...].\n",
    "\n",
    "### a) Ending in ise\n",
    "### b) Containing the letter z\n",
    "### c) Containing the sequence of letters pt\n",
    "### d) Having all lowercase letters except for an initial capital (i.e., titlecase)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wise', 'wise', 'apologise', 'surprise', 'surprise', 'surprise', 'noise', 'surprise']\n",
      "['zone', 'amazes', 'Fetchez', 'Fetchez', 'zoop', 'zoo', 'zhiv', 'frozen', 'zoosh']\n",
      "['empty', 'aptly', 'Thpppppt', 'Thppt', 'Thppt', 'empty', 'Thppppt', 'temptress', 'temptation', 'ptoo', 'Chapter', 'excepting', 'Thpppt']\n",
      "['Whoa', 'Halt', 'Who', 'It', 'I', 'Arthur', 'Uther', 'Pendragon', 'Camelot', 'King']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in text6 if w.endswith('ise')])\n",
    "print([w for w in text6 if 'z' in w])\n",
    "print([w for w in text6 if 'pt' in w])\n",
    "print([w for w in text6 if w.istitle()][:10]) # sliced for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 25\n",
    "\n",
    "Define `sent` to be the list of words `['she', 'sells', 'sea', 'shells', 'by', 'the', 'sea', 'shore']`. Now write code to perform the following tasks:\n",
    "\n",
    "### a) Print all words beginning with sh\n",
    "### b) Print all words longer than four characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'shells', 'shore']\n",
      "['sells', 'shells', 'shore']\n"
     ]
    }
   ],
   "source": [
    "sent = ['she', 'sells', 'sea', 'shells', 'by', 'the', 'sea', 'shore']\n",
    "print([w for w in sent if w.startswith('sh')])\n",
    "print([w for w in sent if len(w) > 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 26 \n",
    "\n",
    "What does the following Python code do? `sum(len(w) for w in text1)` Can you use it to work out the average word length of a text?\n",
    "\n",
    "The code will sum up the lengths of each word token in the text. If we divide it by `len(text1)` we'll get the average word length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 999044\n",
      "Average word length: 3.830411128023649\n"
     ]
    }
   ],
   "source": [
    "total = sum(len(w) for w in text1)\n",
    "print(f\"Total: {total}\")\n",
    "print(f\"Average word length: {total / len(text1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 27\n",
    "\n",
    "Define a function called `vocab_size(text)` that has a single parameter for the text, and which returns the vocabulary size of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_size(text):\n",
    "    return len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19317\n",
      "6833\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size(text1))\n",
    "print(vocab_size(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 28\n",
    "\n",
    "Define a function `percent(word, text)` that calculates how often a given word occurs in a text, and expresses the result as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(word, text):\n",
    "    return sum(1 for w in text if w == word) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent('sea', sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 29\n",
    "\n",
    "We have been using sets to store vocabularies. Try the following Python expression: `set(sent3) < set(text1)`. Experiment with this using different arguments to `set()`. What does it do? Can you think of a practical application for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(set(sent3) < set(text1))\n",
    "print(set(sent) < set(text2))\n",
    "print(set(text2[:10]) < set(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inequality operators for sets are for 'subset of' and 'contains' relations. This can be helpful if we want to konw if one collection of strings is a subset of another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
